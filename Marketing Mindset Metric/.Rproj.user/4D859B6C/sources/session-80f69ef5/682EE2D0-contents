head(MindSetDF)
df <- MindSetDF

# if I create a useless column, use that
# df <- df[, -which(names(df) == "test_consideration")]
head(df)
summary(df)
# Note (how to add interactions): 
#   - adding pairwise interaction: (log(factor1) + log(factor2) + etc)^2
#   - adding full interactions: factor1 * factor2 * etc


# Calculate potential for awareness and consideration
potential_awareness <- (100- mean(df$Awareness))/100
potential_awareness

# Calculate potential for liking and consideration
# We have negative and positive values, so I don't know exactly the meaning.



df$liking_transformed <- 50 + df$Liking
summary(df$liking_transformed)

potential_liking <- (100- mean(df$liking_transformed))/100
potential_liking

# What makes most sense is considering that the values represent is a relative % deviation from an reference value.
# Note: just being an absolute deviation would also work fine. We just need something to work with.
# Since this means that there is no theoretical maximum, let's just use the maximum from each one
# Note: I just hope that this is not the case for awareness. Fucking raw data with no explanation...

# OK, actually negative values fuck the log regression, so let's go with data centered around 100 
# (to get 100% as our reference). To avoid rescaling the variance, 
# we'll consider that the values were already percentage deviations

# Final stance: we consider it as % deviation from daily awareness values: 
# we get natural min and max + we get interpretability


# creating a new consideration column


df$consideration_transformed <-  df$Consideration+50
summary(df$consideration_transformed)

potential_consideration <- (100- mean(df$consideration_transformed))/100
potential_consideration

# store the values in a dataframe
table_potential<-data.frame(
  potential=c("awareness", "consideration","liking"), value = c(potential_awareness, potential_consideration, potential_liking)
)

table_potential


# STICKINESS

#awareness
ar1 <- ar(df$Awareness, aic = TRUE)
ar1

#consideration
ar2 <- ar(df$consideration_transformed, aic = TRUE)
ar2

#liking
ar3 <- ar(df$liking_transformed, aic = TRUE)
ar3

# Observation: very high variance for the error in consideration and liking

stick_awareness <- sum(unlist(ar1$ar))
stick_consideration <- sum(unlist(ar2$ar))
stick_liking <- sum(unlist(ar3$ar))
stick_awareness
stick_consideration
stick_liking

# Observation: negative stickiness could mean that it reverts back to 0 over time. There would be no stickiness
# it seems to come from the high volatility of liking and consideration.


# RESPONSIVENESS


#We start by generating lagged variables for each mindset metric and sales

df$lag_aware<-lag(df$Awareness)
df$lag_aware[1]<-0
df$lag_consideration <-lag(df$consideration_transformed)
df$lag_consideration[1]<-0
df$lag_liking <-lag(df$liking_transformed)
df$lag_liking[1]<-0
df$lag_sales <-lag(df$Sales)
df$lag_sales[1]<-0



# The dataframe represents daily data, I think that any marketing variable takes a bit more than 1 day to have an effect
# we need to add a lag for each one

# well, actually, if the KPI they use for awareness, consideration and liking are tractable right after an add, maybe it 
# makes sense to not look at the lagged metrics (since it's supposed to be short-term responsiveness)



#Now estimate the log-linear model
# @TODO: add interaction => ok but it becomes weird
# @TODO: 



response_aware <- lm(log(df$Awareness+1)~log(df$lag_aware+1) + log(df$InstagramAds+1) + log(df$TikTokAds+1) + log(df$SEA+1) + log(df$PoSPromotions+1) + log(df$InfluencerColabs+1), data = df)

response_consideration <- lm(log(df$consideration_transformed+1)~log(df$lag_consideration+1)+log(df$InstagramAds+1)+log(df$TikTokAds+1)+log(df$SEA+1)+log(df$PoSPromotions+1)+log(df$InfluencerColabs+1), data = df)

response_liking <- lm(log(df$liking_transformed+1)~log(df$lag_liking+1)+log(df$InstagramAds+1)+log(df$TikTokAds+1)+log(df$SEA+1)+log(df$PoSPromotions+1)+log(df$InfluencerColabs+1), data = df)

response_sales <- lm(log(df$Sales+1)~log(df$lag_sales+1)+log(df$InstagramAds+1)+log(df$TikTokAds+1)+log(df$SEA+1)+log(df$PoSPromotions+1)+log(df$InfluencerColabs+1), data = df)

# Observation: I have missing values when using un-transformed liking and consideration => the log can't be computed


#Summarize all the regression results here:
summary(response_aware)
summary(response_consideration)
summary(response_liking)
summary(response_sales)
# pretty bad R-squared, but it's normal for that kind of regression. It doesn't matter.

table_response_aware<-data.frame(round(response_aware$coefficients,5))
table_response_liking<-data.frame(round(response_liking$coefficients,5))
table_response_consideration<-data.frame(round(response_consideration$coefficients,5))
table_response_sales<-data.frame(round(response_sales$coefficients,5))

table_response_aware
table_response_consideration
table_response_liking
table_response_sales


# CONVERSION

# how are sales driven by mindset ?
# @TODO: add interaction between metrics => ok but actually how do I interpret an interaction between metrics
# @TODO: add direct/indirect effect between metrics (e.g. awareness -> consideration -> sales)


conversion <- lm(log(df$Sales+1)~log(lag_sales+1)+log(df$Awareness+1)+log(df$consideration_transformed+1)+log(df$liking_transformed+1), data = df)
summary(conversion)

table_conversion <-data.frame(round(conversion$coefficients,5))
table_conversion


# RESULTS

table_final<-data.frame(
  Item = c("beginning level", "potential", "stickiness", "responsiveness to insta", "responsiveness to tiktok", "responsiveness to SEA", "responsiveness to PoSPromotion", "responsiveness to influencer colabs", "conversion"), 
  awareness=c(round(mean(df$Awareness)/100,3),round(potential_awareness,3),round(stick_awareness,3),round(response_aware$coefficients[3],5),	round(response_aware$coefficients[4],5),round(response_aware$coefficients[5],5),round(response_aware$coefficients[6],5),round(response_aware$coefficients[7],5),round(conversion$coefficients[3],3)), 
  consideration=c(round(mean(df$consideration_transformed)/100,3), round(potential_consideration,3), round(stick_consideration,3),round(response_consideration$coefficients[3],5),round(response_consideration$coefficients[4],5),round(response_consideration$coefficients[5],5),round(response_consideration$coefficients[6],5),round(response_consideration$coefficients[7],5),round(conversion$coefficients[4],3)), 
  liking = c(round(mean(df$liking_transformed)/100,3), round(potential_liking,3), round(stick_liking,3),round(response_liking$coefficients[3],5), round(response_liking$coefficients[4],5), round(response_liking$coefficients[5],5), round(response_liking$coefficients[6],5), round(response_liking$coefficients[7],5),round(conversion$coefficients[5],3))
)


table_final

# negative responsiveness : either the response is lagged (it only shows the day after, so we should lag it)
# either people consider/like the brand less after the thing (but I don't know about awareness though)

# negative conversion of awareness => WTF ?

tail(df)
# APPEAL

# I'm using functions to make it easier

appeal_mindset_marketVar <- function(mindset, marketing_var_index){
  appeal <- round(table_final[2,mindset]*table_final[marketing_var_index,mindset]*(1/(1-table_final[3,mindset]))*table_final[9,mindset],5)
  return(appeal)
}

appeal_marketVar <- function(marketing_var_index) {
  mindsets <- c("awareness", "consideration", "liking")
  result <- sum(sapply(mindsets, appeal_mindset_marketVar, marketing_var_index=marketing_var_index))
  return(result)
}


appeal_marketVar(4) # insta
appeal_marketVar(5) # tiktok
appeal_marketVar(6) # sea
appeal_marketVar(7) # pospromotion
appeal_marketVar(8) # colabs